---
title: Definitions
date: 2026-01-15T09:31:35.184Z
tags:
  - ML
categories:
  - ML
slug: definitions
---

To understand the basis for probability theory, it is important to fully understand every term used. here are the definitions for the terms we will be using.

## Set Theory/Topology

### Power Set

A power set $\mathcal{P}(S)$ of set $S$ is the set of all subsets of $S$. An example set $S$ can include $S = \{1,2,3\}$, The power set will therefore be $\mathcal{P}(S) = \{\emptyset, \{1\}, \{2\}, \{3\}, \{1,2\}, \{1,3\}, \{2,3\}, \{1,2,3\}\}$

### Topology

In this context, topology $\tau$ on $S$ is a collection $\tau \subseteq \mathcal{P}(S)$, called open sets, satisfying:

1. Triviality, $\emptyset, S \in \tau$

2. Finite intersection: $U_1, \dots, U_n \in \tau \implies \bigcap^n_{i=1} U_i \in \tau, n\in \mathbb{N}$

3. Arbitrary union: For any collection of open sets $\{U_a\}_{a\in A} \subseteq \tau$, the union $\bigcup_{a\in A} U_a \in \tau$, where $A$ is an arbitrary index set.

### Topological Space

The tuple $(S, \tau)$ is called a topological space where all elements $U \in \tau$ are open sets.

### Measurable Space

A measurable space is a tuple ($\Omega, \mathcal{F}$) consist of any non-empty set (sample space) $\Omega$ and $\sigma$-algebra $\mathcal{F} \subseteq \mathcal{P}(\Omega)$, a sub-collection of the power set of $\Omega$ whose elements are called measurable sets, where $\mathcal{F}$ satisfies:

$$
\begin{align}
  \Omega \in \mathcal{F}\\
  A \in \mathcal{F} \implies A^c \in \mathcal{F}\\
  A_1, A_2, \dots \in \mathcal{F} \implies \bigcup^\infty_{i=1} A_i \in \mathcal{F}
\end{align}
$$

:::info
**Why condition 3 is necessary:**
Consider the sample space $\Omega = \{1, 2, 3\}$.
Let a collection of sets be $\mathcal{G} = \{\emptyset, \{1\}, \{2\}, \{2,3\}, \{1,3\}, \{1,2,3\} \}$.
Check complements: $\{1\}^c = \{2,3\} \in \mathcal{G}$. All complements are present.
However, check unions: $\{1\} \in \mathcal{G}$ and $\{2\} \in \mathcal{G}$, but $\{1\} \cup \{2\} = \{1,2\}$.
$\{1,2\}$ is **not** in $\mathcal{G}$.
Without being closed under union, we could assign probabilities to outcomes "1" and "2" individually, but fail to assign a probability to the event "1 or 2". A $\sigma$-algebra guarantees this is defined.
:::

### Generated $\sigma$-algebra

let $\mathcal{C} \subseteq \mathcal{P}(S)$ by any collection of subsets of $S$, the $\sigma$-algebra generated by $\mathcal{C}$, denoted $\sigma(\mathcal{C})$ is the intersection of all $\sigma$-algebras containing $\mathcal{C}$, hence the smallest $\sigma$-algebra containing $\mathcal{C}$. This is denoted:

$$
\begin{equation}
  \sigma(\mathcal{C}) = \bigcap \left\{\mathcal{G}:\mathcal{C} \subseteq \mathcal{G}, \mathcal{G} \text{ is a $\sigma$-algebra on }S \right\}
\end{equation}
$$

### Borel $\sigma$-algebra

Let $(S, \tau)$ be a topological space, the Borel $\sigma$-algebra, denoted $\mathcal{B}(S)$, is the $\sigma$-algebra generated by topology $\tau$:

$$
\begin{equation}
  \mathcal{B}(S) = \sigma (\tau)
\end{equation}
$$

## Measure Theory

### Measure

In a measurable space ($\Omega, \mathcal{F}$), a measure is a function $\mu : \mathcal{F} \rightarrow [0,\infty]$, satisfying:

1. Null empty set: $\mu(\emptyset) = 0$
2. Countable additivity: For any countable collection of pairwise disjoint sets $\{A_i\}^\infty_{i=1} \subseteq \mathcal{F}$:

$$
\mu \left(\bigcup^\infty_{i=1} A_i\right) = \sum^\infty_{i=1} \mu (A_i)
$$

### $\sigma$-finite Measure

A measure $\mu$ on $(\Omega, \mathcal{F})$ is $\sigma$-finite if $\Omega$ can be written as a countable union of measurable sets with finite measures:

$$
\Omega = \bigcup^\infty_{n=1} A_n, \quad A_n \in \mathcal{F}, \quad \mu(A_n) < \infty
$$

### Probability Measure

Probabilities measures $P$ on $(\Omega, \mathcal{F})$, $P:\mathcal{F} \rightarrow [0,1]$ are confined to the codomain $[0,1]$ as all probabilities are real numbers within $[0,1]$. To ensure the countable additivity holds, the probability measure is normalized such that $P(\Omega)=1$.

### Space of Probability Measure

let $(S, \mathcal{B}(S))$ be a measurable space, the space of probability measures $\mathcal{M}_1(S, \mathcal{B}(S))$ is the set of all probability measures where $\forall \mu_i \in \mathcal{M}_1, \space \mu_i: \mathcal{B}(S) \rightarrow [0,1]$.

:::info
$\mathcal{M}_1$ chosen for probability measurements here due to value being normalize with $\mu_i(S) = 1$
:::

### Probability Space

A probability space is a tuple ($\Omega, \mathcal{F}, P$), where $(\Omega, \mathcal{F})$ is the measurable space defined previously and $P$ is the probability measure where $P \in \mathcal{M}_1(\Omega, \mathcal{F})$.

### Outcome

Outcome $\omega \in \Omega$ is an element of some space $\Omega$.

## Probability Properties

### Event

Given a measurable space ($\Omega, \mathcal{F}$), an event is a measurable set $A \in \mathcal{F}$ where the probability measure is $P(A)$.

### Elementary Event

Elementary event is a set containing a single outcome, $\{\omega\} \subset \Omega$. Here we assume elementary events also only contain measurable elements: $\{\omega\} \in \mathcal{F}$.

:::info
This assumption is based in the fact that with a topological space equipped with a Borel $\sigma$-algebra, singletons are measurable if the space is $T_1$ (Frechet). Most ML spaces are $T_2$ (Hausdorff) or Metric spaces anyways, which implies $T_1$
:::

#### Complementary

We denote complement of an event as $A^c = \Omega \setminus A$:

$$
P(A \cup A^c) = P(\Omega)=1
$$

#### Joint Probability

If two events $A, B \in \mathcal{F}$ the probability of their intersection is denoted $P(A \cap B)$. Using the additivity of measures, the inclusion-exclusion principle is as follows:

$$
P(A \cup B) = P(A) + P(B) - P(A \cap B)
$$

:::info
You are reminded that mutually exclusive events have the property $P(A \cap B) = 0$
:::

#### Conditional Probability

For events $A, B \in \mathcal{F}, P(B) > 0$, the conditional probability of $A$ given $B$ is defined as the normalized measure of the intersection:

$$
P(A|B) \triangleq \frac{P(A\cap B)}{P(B)}
$$

## Random Elements and Distribution

### Random Element

The random sources can exist in other probability space than real numbers, random variable (strictly real number domain) is not enough to measure the full domain of a random source. Therefore, random element should be strictly defined. Let $(\Omega, \mathcal{F})$ be a measurable space of random source, and $(S, \mathcal{B}(S))$ be a measurable space of target. A function $X:\Omega \rightarrow S$ is a random element if it is ($\mathcal{F}, \mathcal{B}(S)$)-measurable:

$$
\forall B \in \mathcal{B}(S), X^{-1}(B) \in \mathcal{F}
$$

### The Law/Induced Distribution

The Law of random element $X$ is the probability measure $P_x \in \mathcal{M}(S, \mathcal{B}(S))$, defined by the pushforward $P$:

$$
P_X(B) = P(X^{-1}(B))
$$

### Product Measure

Let $(\Omega_1, \mathcal{F}_1, \mu_1)$ and ($\Omega_2, \mathcal{F}_2, \mu_2$) be two $\sigma$-finite measure spaces. The product $\sigma$-algebra, denoted $\mathcal{F}_1 \otimes \mathcal{F}_2$ is the $\sigma$-algebra generated by measurable rectangles $A \times B$ where $A \in \mathcal{F}_1, B \in \mathcal{F}_2$. There exists a unique measure $\pi = \mu_1 \otimes \mu_2$ on $\mathcal{F}_1 \otimes \mathcal{F}_2$ such that for all measurable rectanges:

$$
\begin{equation}
  \pi(A \times B) = \mu_1(A)\mu_2(B)
\end{equation}
$$

### Banach Space

A Banach space $(\mathbb{V}, \parallel \cdot \parallel)$ is a vector space $\mathbb{V}$ equipped with a norm $\parallel$ that is complete. "Complete" refer to every Cauchy sequence in $\mathbb{V}$ converges to a limit within $\mathbb{V}$. An example being $\mathbb{R}^d$ with Euclidean norm together is a Banach space

### Lp Spaces

Let $(\Omega, \mathcal{F}, \mu)$ be a measure space. For $p \in \mathbb{R}_{\geq1}$, the space $\mathcal{L}^p(\Omega, \mathcal{F}, \mu)$ consist of all measurable functions $f:\Omega \rightarrow \mathbb{R}$ such that $\int_\Omega \left\vert f \right\vert^p d\mu < \infty$. The space $L^p$ is the quotient space of $\mathcal{L}^p$ modulo the equivalence relation $f \sim g \iff f = g$ almost everywhere.

## Integration and expectation

### Simple Function

A function $s: \Omega \rightarrow \mathbb{R}$ is a simple function if it takes on a finite number of non-negative values. This can be written as a linear combination of indicator functions:

$$
s(\omega) = \sum^n_{i=1} \alpha_i 1_A (\omega), \quad \alpha_i \in \reals_{\geq 0}, \quad A_i \in \mathcal{F}
$$

where $a_i$ and $A_i$ are disjoint measurable sets.

### Lebesgue Integral

This is a integral constructed from $3$ steps:

1. Simple functions: Given a simple function $s=\sum \alpha_i 1_A$, the integral is $\int s d\mu = \sum^n_i=1 \alpha_i \mu (A_i)$.
2. Non-negative Measurable Functions: For any $f: \Omega \rightarrow [0, \infty]$, defined as the supremum of integrals of simple functions bounded by f:
   $$
   \int f d\mu = sup \left\{\int s d\mu : 0\leq s \leq f, s \text{ is simple}\right\}
   $$
3. General Measurable Functions: For $f: \Omega \rightarrow \reals$, decompose into positive and negative parts $f = f^+ - f^-$. If both parts have finite integrals, $f$ is integrable and:
   $$
   \int f d \mu = \int f^+ d\mu - \int f^- d\mu
   $$

### Expectation

Expectations is only define for Banach spaces. Given a probability space ($\Omega,\mathcal{F}, P$), where $\mathcal{F} \subseteq \reals^n$, for a random element $X: \Omega \rightarrow \mathcal{F}$, the expectation (expected value) is the bochner integral of $X$ with respect to probability measure $P$:

$$
\mathbb{E}[X] = \int_\Omega X(\omega)dP(\omega), \quad \omega \in \Omega
$$

### Absolute Continuous Random Element

$X$ is a absolute continuous random element with respect to Lebesgue measure $\lambda$ if $P_X \ll \lambda$. This is indicated by:

$$
P_X \ll \lambda \iff (\forall B \in \mathcal{B}(S), \lambda(B)=0 \implies P_X (B) = 0)
$$

### Radon-Nikodym Derivative

Let $\mu$ and $v$ be two $\sigma$-finite measures on $(\Omega, \mathcal{F})$. If $v \ll \mu$, there exists a measurable function $f:\Omega \rightarrow [0, \infty)$, denoted $f = \frac{dv}{d \mu}$, such that for every $A \in \mathcal{F}$:

$$
v(A) = \int_A f d\mu
$$

## Onvergence Almost Surely

A sequence of random variables $X_n$ converges almost surely to $X$ if the event where they differ has a probability $0$:

$$
P\left(\left\{\omega \in \Omega: \lim_{n\rightarrow \infty} X_n (\omega) = X(\omega)\right\}\right)= 1
$$

### Reference Measure

The reference measure $\lambda$ is a standard for volume, a $\sigma$-finite measure on $(S, \mathcal{B}(S))$

### Topological Measurable Space

Topological Measurable Space is a tuple $(S, \tau, \mathcal{B}(S))$, where $S$ is a set, $\tau$ is a topology on $S$, $\mathcal{B}(S)$ is the Borel $\sigma$-algebra generated by $\tau$

### Probability Density Function

If $P_X \ll \lambda$, the probability density function would be the Radon-Nikodym derivative $f=\frac{d P_X}{d \lambda}$, satisfying:

$$
\begin{equation}
  P_X(B) = \int_B f \space d \lambda
\end{equation}
$$

### Parameter space

A parameter space is simply a measurable space $(\Theta, \mathcal{A})$.

### Parametrization

A parametrization $\psi$ is a mapping $\psi: \Theta \rightarrow \mathcal{M}_1(S, \mathcal{B}(S))$ that assigns a probability measure on each parameter $\Theta$. We denote the measure $P_\theta = \psi(\theta)$.

### Parameter

A parameter is an element $\theta \in \Theta$ used as an argument for $\psi$.

### Statistical Model

A statistical model is the image of parametrization: $\mathcal{Q}= \{P_\theta \in \mathcal{M}(S, \mathcal{B}(S)) : P_\theta = \psi(\theta), \theta \in \Theta\}$

### Dominated Statistical Model

The model $\mathcal{Q}_\theta : \theta \in \Theta$ is called dominated if there exists a $\sigma$-finite reference measure $\lambda$ such that $\forall \theta \in \Theta, P_\theta \ll \lambda$.

### Likelihood Function

Given a dominated model with reference measure \lambda, the Radon-Nikodym derivative $p(s|\theta) = \frac{d P_\theta}{d\lambda}(s)$ exists. For a fixed observation $s\in S$, the likelihood function $L_s: \Theta \rightarrow [0, \infty)$ is defined by:

$$
\begin{equation}
 L_s(\theta) = p(s|\theta)
\end{equation}
$$

### Probability

All mathematical axioms above are accpeted by all schools, but there are a divide on the interprestation of probability measure $P$ and the nature of parameter $\theta$. These divide are based on the Frequentist and Bayesian interpretations.

#### Frequentist

Frequentist view probability as a expected fraction of frequency of event occurring as the number of repetition approaches infinity. This leads to the following viewpoints:

The measure $P(A)$ represent the limit of relative frequency of event $A$ in an infinite sequence of identical, independent repetition of the experiment.

The parameter $\theta$ is fixed, non-random element of the set $\Theta$, an unknown constant of nature. A probability measure on $\Theta$ will therefore be undefined.

#### Bayesian

Bayesian interpretation views probability as the degree of belief of an event occurring. With the viewpoints:

The measure $P(A)$ represent a degree of belief of event $A$ given the current state of information.

The parameter $\theta$ is a random element $X$ mapping from underlying probability space $\Omega$ to parameter space $\Theta$.

:::info
In practice, we often work directly with a prior probability measure defined on the prameter space $\Theta$
:::

### Kullback-Leibler Divergence

Let $P$ and $Q$ be two probability measures on $(S, \mathcal{B}(S))$. If $P \ll Q$ (P is absolutely continuous with respect to Q), the KL divergence is defined using the Radon-Nikodym derivative $\frac{dP}{dQ}$:

$$
D_{KL}(P \| Q) = \int_S \log \left( \frac{dP}{dQ} \right) \, dP
$$

If $P$ is not absolutely continuous with respect to $Q$, $D_{KL}(P \| Q) = \infty$.

#### Markov Kernel / Transition Kernel

Fundamental for MCMC and Diffusion Models.

### Markov Kernel

Let $(S, \mathcal{S})$ and $(T, \mathcal{T})$ be measurable spaces. A function $\kappa: S \times \mathcal{T} \to [0, 1]$ is a **Markov Kernel** (or probability kernel) if:

1. For every fixed $B \in \mathcal{T}$, the map $s \mapsto \kappa(s, B)$ is $\mathcal{S}$-measurable.
2. For every fixed $s \in S$, the map $B \mapsto \kappa(s, B)$ is a probability measure on $(T, \mathcal{T})$.

### Uncertainty

#### Epistemic/Model Uncertainty

The uncertainty led by ignorance of underlying causes or mechanism generating data.

#### Aleatoric/Data Uncertainty

Intrinsic variability that cannot be reduced even with a larger data set. For example, a coin toss have a probability of $p = 0.5$, there are no epistemic uncertainty here but the outcome is unpredictable because of data uncertainty.

### Regular Conditional Distribution

Instead of asking "What is the expected value of $X$ given $\mathcal{G}$?", we ask "What is the **full distribution** of $X$ given $\mathcal{G}$?". Let $(\Omega, \mathcal{F}, P)$ be a probability space, let $(S, \mathcal{S})$ be a measurable space (the target space of our random element), and let $X: \Omega \to S$ be a Random Element. Let $\mathcal{G} \subseteq \mathcal{F}$ be a sub-$\sigma$-algebra.

A **Regular Conditional Distribution** (or Conditional Kernel) of $X$ given $\mathcal{G}$ is a function $\kappa: \Omega \times \mathcal{S} \to [0, 1]$ such that:

1. **Measure:** For almost every fixed $\omega \in \Omega$, the map $B \mapsto \kappa(\omega, B)$ is a probability measure on $(S, \mathcal{S})$.
2. **Measurability:** For every fixed set $B \in \mathcal{S}$, the map $\omega \mapsto \kappa(\omega, B)$ is $\mathcal{G}$-measurable.
3. **Consistency:** For every $B \in \mathcal{S}$ and $G \in \mathcal{G}$:
   $$
   \int_G \kappa(\omega, B) \, dP(\omega) = P(X^{-1}(B) \cap G)
   $$

### Conditional Expectation

If $S$ is a Banach space (e.g., $\mathbb{R}^n$) and $X$ is integrable, the Conditional Expectation $E[X|\mathcal{G}]$ is defined as the expectation of the Regular Conditional Distribution $\kappa$:

$$
E[X|\mathcal{G}](\omega) = \int_S s \, \kappa(\omega, ds)
$$

### Conditional Fréchet Mean

If $S$ is a metric space $(S, d)$, the Conditional Fréchet Mean is the minimizer of the **conditional** Fréchet variance.
Given the Regular Conditional Distribution $\kappa(\omega, \cdot)$ defined above:

$$
\mu_{\mathcal{G}}(\omega) = \underset{y \in S}{\arg\min} \int_S d^2(y, s) \, \kappa(\omega, ds)
$$

#### Marginal Independence

A finite collection of events $A_1, \dots, A_n \in \mathcal{F}$ is marginal independent if for every subset of indices $I \subseteq \{1, \dots, n\}$:

$$
P\left(\bigcap_{i\in I} A_i\right) = \prod_{i\in I}P(A_i)
$$

#### Conditional Independence

Given that event $C \in \mathcal{F}$ holds, event $A, B \in \mathcal{F}$ are conditionally independent if:

$$
P(A\cap B| C) = P(A|C)P(B|C)
$$

This is often denoted as $A \perp B | C$.

TODO: Definitions for random variable, kernel, Markov kernels, convergence, weak convergence, Kullback-Leibler Divergence, non-negative functions, general functions, KL divergence, radon-nikodym derivative, norm, Euclidean norm, cauchy sequence, convergence, quotient space, modulo, equivalence relation, indicator function, disjoint, measurable set, bochner integral
